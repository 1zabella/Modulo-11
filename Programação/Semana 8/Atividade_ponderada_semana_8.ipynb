{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjYcowe7_fQy"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "from transformers import BertTokenizer\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcbiTlXg_i6F"
      },
      "outputs": [],
      "source": [
        "!gdown 1zASdz9hUY6NC6p7h9ef5trbv4B3uUpJr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs43thDw_ksD"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/bot_detection_data.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x9gBwj5ILOr"
      },
      "source": [
        "O dataset contém 50.000 linhas e 11 colunas, sendo elas:\n",
        "\n",
        "* User ID: ID do usuário (numérico).\n",
        "* Username: Nome do usuário (texto).\n",
        "* Tweet: O conteúdo do tweet (texto).\n",
        "* Retweet Count: Contagem de retweets (numérico).\n",
        "* Mention Count: Contagem de menções (numérico).\n",
        "* Follower Count: Contagem de seguidores (numérico).\n",
        "* erified: Indicação se o usuário é verificado (booleano).\n",
        "* Bot Label: Rótulo que indica se é um bot (1) ou não (0) (numérico).\n",
        "* Location: Localização do usuário (texto).\n",
        "* Created At: Data de criação do tweet (texto).\n",
        "* Hashtags: Hashtags utilizadas no tweet (texto)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XcGYVlDEUoa"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIhRB48cAIg_"
      },
      "outputs": [],
      "source": [
        "# Visualizando as primeiras informações dos dados\n",
        "df.head()  # Primeiras linhas do DataFrame\n",
        "df.info()  # Informações sobre os tipos de dados e valores nulos\n",
        "df.describe()  # Estatísticas descritivas das colunas numéricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wKyQWHXIcwL"
      },
      "outputs": [],
      "source": [
        "# Configurando estilo dos gráficos\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Distribuição da variável \"Bot Label\"\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='Bot Label', data=df, palette='Set2')\n",
        "plt.title(\"Distribuição de Bots vs Não Bots\")\n",
        "plt.xlabel(\"Bot Label\")\n",
        "plt.ylabel(\"Contagem\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRXj44K0JJsX"
      },
      "source": [
        "A proporção de bots (1) e não bots (0) está balanceada, com quantidades semelhantes em cada grupo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CCXIhmVPJDQa"
      },
      "outputs": [],
      "source": [
        "# Verificando a distribuição de variáveis numéricas principais com relação à variável alvo\n",
        "plt.figure(figsize=(16, 6))\n",
        "\n",
        "# Subplot para \"Retweet Count\"\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.boxplot(x='Bot Label', y='Retweet Count', data=df, palette='Set3')\n",
        "plt.title(\"Distribuição de Retweets por Bot Label\")\n",
        "\n",
        "# Subplot para \"Mention Count\"\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.boxplot(x='Bot Label', y='Mention Count', data=df, palette='Set3')\n",
        "plt.title(\"Distribuição de Menções por Bot Label\")\n",
        "\n",
        "# Subplot para \"Follower Count\"\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.boxplot(x='Bot Label', y='Follower Count', data=df, palette='Set3')\n",
        "plt.title(\"Distribuição de Seguidores por Bot Label\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkjfDPXLJMK8"
      },
      "source": [
        "**Distribuições de Retweets, Menções e Seguidores por Bot Label:**\n",
        "\n",
        "* **Retweet Count:** Bots tendem a ter uma distribuição de retweets mais alta e com mais outliers, sugerindo que podem estar envolvidos em campanhas de retweet automáticas.\n",
        "* **Mention Count:** A distribuição de menções é semelhante entre bots e não bots, mas com mais variabilidade para os bots.\n",
        "* **Follower Count:** A contagem de seguidores também apresenta uma maior variabilidade entre bots, o que pode indicar a presença de bots com muitos ou poucos seguidores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CRykSIHDFg8D"
      },
      "outputs": [],
      "source": [
        "# A coluna correta é \"Hashtags\" com a letra maiúscula\n",
        "df['Hashtags'] = df['Hashtags'].fillna('None')\n",
        "\n",
        "# Conversão da coluna \"Created At\" para datetime\n",
        "df['created_at'] = pd.to_datetime(df['Created At'], errors='coerce')\n",
        "\n",
        "# Verificar se existem valores nulos após as correções\n",
        "missing_data = df.isnull().sum()\n",
        "\n",
        "# Exibir o resultado do tratamento\n",
        "missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8VN-MWvzFjY6"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Normalizar as colunas numéricas: 'Retweet Count', 'Mention Count', 'Follower Count'\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "df[['Retweet Count', 'Mention Count', 'Follower Count']] = scaler.fit_transform(df[['Retweet Count', 'Mention Count', 'Follower Count']])\n",
        "\n",
        "# Verificar a distribuição do \"Bot Label\" para o balanceamento\n",
        "bot_label_distribution = df['Bot Label'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Exibir a distribuição da variável alvo\n",
        "bot_label_distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN3uFPJMKXj9"
      },
      "source": [
        "## Preparação dos dados para o modelo BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TOhQ4ODhK_tC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFDistilBertForSequenceClassification, DistilBertTokenizer\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPAeP_r5KlSB"
      },
      "outputs": [],
      "source": [
        "# Definir o nome do modelo pré-treinado\n",
        "pretrained_model_name = 'distilbert-base-uncased'\n",
        "\n",
        "# Carregar o tokenizador\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(pretrained_model_name)\n",
        "\n",
        "# Carregar o modelo pré-treinado\n",
        "bert_model = TFDistilBertForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=2)\n",
        "\n",
        "# Pré-processamento dos dados\n",
        "X = df[['Tweet']]  # Usando a coluna de texto 'Tweet'\n",
        "y = df['Bot Label']  # Usando a coluna 'Bot Label' como target\n",
        "\n",
        "# Dividindo o dataset para usar apenas 10% no treinamento\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.1, random_state=42)\n",
        "\n",
        "# Tokenização usando o DistilBERT\n",
        "def encode_tweets(texts, tokenizer, max_len=128):\n",
        "    return tokenizer(\n",
        "        texts.tolist(),\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_len,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='tf'\n",
        "    )\n",
        "\n",
        "train_encodings = encode_tweets(X_train['Tweet'], tokenizer)\n",
        "test_encodings = encode_tweets(X_test['Tweet'], tokenizer)\n",
        "\n",
        "# Convertendo para tensores\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test))\n",
        "\n",
        "# Definir as entradas corretamente\n",
        "input_ids = Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\n",
        "attention_mask = Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "# Lambda layer para encapsular o modelo BERT, especificando o formato de saída explicitamente\n",
        "bert_output = Lambda(lambda x: bert_model.distilbert(input_ids=x[0], attention_mask=x[1])[0],\n",
        "                     output_shape=(128,768))([input_ids, attention_mask])\n",
        "\n",
        "# Adicionando camadas extras ao modelo\n",
        "dropout_layer = Dropout(0.3)(bert_output[:, 0, :])  # Usando apenas o primeiro token [CLS]\n",
        "dense_layer = Dense(128, activation='relu')(dropout_layer)\n",
        "output_layer = Dense(1, activation='sigmoid')(dense_layer)\n",
        "\n",
        "# Criando o modelo final\n",
        "model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output_layer)\n",
        "\n",
        "# Compilar o modelo com otimizador e hiperparâmetros ajustados\n",
        "optimizer = Adam(learning_rate=3e-5)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Resumo da arquitetura do modelo\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYlv5fNYL329"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo com Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Ajuste dos hiperparâmetros e treinamento\n",
        "model.fit(\n",
        "    train_dataset.batch(16),  # Certifique-se que o dataset está sendo carregado corretamente\n",
        "    validation_data=test_dataset.batch(256),\n",
        "    epochs=5,  # Aumentei para 5 épocas\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2-uBkRjL7UO"
      },
      "outputs": [],
      "source": [
        "# Avaliação do modelo\n",
        "loss, accuracy = model.evaluate(test_dataset.batch(16))\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Salvando o modelo treinado\n",
        "model.save(\"/kaggle/working/bert_bot_detection_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3oHPxBlKrdw"
      },
      "outputs": [],
      "source": [
        "# Avaliação do modelo\n",
        "loss, accuracy = model.evaluate(test_dataset.batch(16))\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4mpwOQt4NO3U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}